{"ast":null,"code":"/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Reads in-band CEA-708 captions out of FMP4 segments.\n * @see https://en.wikipedia.org/wiki/CEA-708\n */\n'use strict';\n\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nvar discardEmulationPreventionBytes = require('../tools/caption-packet-parser').discardEmulationPreventionBytes;\n\nvar CaptionStream = require('../m2ts/caption-stream').CaptionStream;\n\nvar probe = require('./probe');\n\nvar inspect = require('../tools/mp4-inspector');\n/**\n  * Maps an offset in the mdat to a sample based on the the size of the samples.\n  * Assumes that `parseSamples` has been called first.\n  *\n  * @param {Number} offset - The offset into the mdat\n  * @param {Object[]} samples - An array of samples, parsed using `parseSamples`\n  * @return {?Object} The matching sample, or null if no match was found.\n  *\n  * @see ISO-BMFF-12/2015, Section 8.8.8\n **/\n\n\nvar mapToSample = function mapToSample(offset, samples) {\n  var approximateOffset = offset;\n\n  for (var i = 0; i < samples.length; i++) {\n    var sample = samples[i];\n\n    if (approximateOffset < sample.size) {\n      return sample;\n    }\n\n    approximateOffset -= sample.size;\n  }\n\n  return null;\n};\n/**\n  * Finds SEI nal units contained in a Media Data Box.\n  * Assumes that `parseSamples` has been called first.\n  *\n  * @param {Uint8Array} avcStream - The bytes of the mdat\n  * @param {Object[]} samples - The samples parsed out by `parseSamples`\n  * @param {Number} trackId - The trackId of this video track\n  * @return {Object[]} seiNals - the parsed SEI NALUs found.\n  *   The contents of the seiNal should match what is expected by\n  *   CaptionStream.push (nalUnitType, size, data, escapedRBSP, pts, dts)\n  *\n  * @see ISO-BMFF-12/2015, Section 8.1.1\n  * @see Rec. ITU-T H.264, 7.3.2.3.1\n **/\n\n\nvar findSeiNals = function findSeiNals(avcStream, samples, trackId) {\n  var avcView = new DataView(avcStream.buffer, avcStream.byteOffset, avcStream.byteLength),\n      result = [],\n      seiNal,\n      i,\n      length,\n      lastMatchedSample;\n\n  for (i = 0; i + 4 < avcStream.length; i += length) {\n    length = avcView.getUint32(i);\n    i += 4; // Bail if this doesn't appear to be an H264 stream\n\n    if (length <= 0) {\n      continue;\n    }\n\n    switch (avcStream[i] & 0x1F) {\n      case 0x06:\n        var data = avcStream.subarray(i + 1, i + 1 + length);\n        var matchingSample = mapToSample(i, samples);\n        seiNal = {\n          nalUnitType: 'sei_rbsp',\n          size: length,\n          data: data,\n          escapedRBSP: discardEmulationPreventionBytes(data),\n          trackId: trackId\n        };\n\n        if (matchingSample) {\n          seiNal.pts = matchingSample.pts;\n          seiNal.dts = matchingSample.dts;\n          lastMatchedSample = matchingSample;\n        } else {\n          // If a matching sample cannot be found, use the last\n          // sample's values as they should be as close as possible\n          seiNal.pts = lastMatchedSample.pts;\n          seiNal.dts = lastMatchedSample.dts;\n        }\n\n        result.push(seiNal);\n        break;\n\n      default:\n        break;\n    }\n  }\n\n  return result;\n};\n/**\n  * Parses sample information out of Track Run Boxes and calculates\n  * the absolute presentation and decode timestamps of each sample.\n  *\n  * @param {Array<Uint8Array>} truns - The Trun Run boxes to be parsed\n  * @param {Number} baseMediaDecodeTime - base media decode time from tfdt\n      @see ISO-BMFF-12/2015, Section 8.8.12\n  * @param {Object} tfhd - The parsed Track Fragment Header\n  *   @see inspect.parseTfhd\n  * @return {Object[]} the parsed samples\n  *\n  * @see ISO-BMFF-12/2015, Section 8.8.8\n **/\n\n\nvar parseSamples = function parseSamples(truns, baseMediaDecodeTime, tfhd) {\n  var currentDts = baseMediaDecodeTime;\n  var defaultSampleDuration = tfhd.defaultSampleDuration || 0;\n  var defaultSampleSize = tfhd.defaultSampleSize || 0;\n  var trackId = tfhd.trackId;\n  var allSamples = [];\n  truns.forEach(function (trun) {\n    // Note: We currently do not parse the sample table as well\n    // as the trun. It's possible some sources will require this.\n    // moov > trak > mdia > minf > stbl\n    var trackRun = inspect.parseTrun(trun);\n    var samples = trackRun.samples;\n    samples.forEach(function (sample) {\n      if (sample.duration === undefined) {\n        sample.duration = defaultSampleDuration;\n      }\n\n      if (sample.size === undefined) {\n        sample.size = defaultSampleSize;\n      }\n\n      sample.trackId = trackId;\n      sample.dts = currentDts;\n\n      if (sample.compositionTimeOffset === undefined) {\n        sample.compositionTimeOffset = 0;\n      }\n\n      sample.pts = currentDts + sample.compositionTimeOffset;\n      currentDts += sample.duration;\n    });\n    allSamples = allSamples.concat(samples);\n  });\n  return allSamples;\n};\n/**\n  * Parses out caption nals from an FMP4 segment's video tracks.\n  *\n  * @param {Uint8Array} segment - The bytes of a single segment\n  * @param {Number} videoTrackId - The trackId of a video track in the segment\n  * @return {Object.<Number, Object[]>} A mapping of video trackId to\n  *   a list of seiNals found in that track\n **/\n\n\nvar parseCaptionNals = function parseCaptionNals(segment, videoTrackId) {\n  // To get the samples\n  var trafs = probe.findBox(segment, ['moof', 'traf']); // To get SEI NAL units\n\n  var mdats = probe.findBox(segment, ['mdat']);\n  var captionNals = {};\n  var mdatTrafPairs = []; // Pair up each traf with a mdat as moofs and mdats are in pairs\n\n  mdats.forEach(function (mdat, index) {\n    var matchingTraf = trafs[index];\n    mdatTrafPairs.push({\n      mdat: mdat,\n      traf: matchingTraf\n    });\n  });\n  mdatTrafPairs.forEach(function (pair) {\n    var mdat = pair.mdat;\n    var traf = pair.traf;\n    var tfhd = probe.findBox(traf, ['tfhd']); // Exactly 1 tfhd per traf\n\n    var headerInfo = inspect.parseTfhd(tfhd[0]);\n    var trackId = headerInfo.trackId;\n    var tfdt = probe.findBox(traf, ['tfdt']); // Either 0 or 1 tfdt per traf\n\n    var baseMediaDecodeTime = tfdt.length > 0 ? inspect.parseTfdt(tfdt[0]).baseMediaDecodeTime : 0;\n    var truns = probe.findBox(traf, ['trun']);\n    var samples;\n    var seiNals; // Only parse video data for the chosen video track\n\n    if (videoTrackId === trackId && truns.length > 0) {\n      samples = parseSamples(truns, baseMediaDecodeTime, headerInfo);\n      seiNals = findSeiNals(mdat, samples, trackId);\n\n      if (!captionNals[trackId]) {\n        captionNals[trackId] = [];\n      }\n\n      captionNals[trackId] = captionNals[trackId].concat(seiNals);\n    }\n  });\n  return captionNals;\n};\n/**\n  * Parses out inband captions from an MP4 container and returns\n  * caption objects that can be used by WebVTT and the TextTrack API.\n  * @see https://developer.mozilla.org/en-US/docs/Web/API/VTTCue\n  * @see https://developer.mozilla.org/en-US/docs/Web/API/TextTrack\n  * Assumes that `probe.getVideoTrackIds` and `probe.timescale` have been called first\n  *\n  * @param {Uint8Array} segment - The fmp4 segment containing embedded captions\n  * @param {Number} trackId - The id of the video track to parse\n  * @param {Number} timescale - The timescale for the video track from the init segment\n  *\n  * @return {?Object[]} parsedCaptions - A list of captions or null if no video tracks\n  * @return {Number} parsedCaptions[].startTime - The time to show the caption in seconds\n  * @return {Number} parsedCaptions[].endTime - The time to stop showing the caption in seconds\n  * @return {String} parsedCaptions[].text - The visible content of the caption\n **/\n\n\nvar parseEmbeddedCaptions = function parseEmbeddedCaptions(segment, trackId, timescale) {\n  var seiNals; // the ISO-BMFF spec says that trackId can't be zero, but there's some broken content out there\n\n  if (trackId === null) {\n    return null;\n  }\n\n  seiNals = parseCaptionNals(segment, trackId);\n  return {\n    seiNals: seiNals[trackId],\n    timescale: timescale\n  };\n};\n/**\n  * Converts SEI NALUs into captions that can be used by video.js\n **/\n\n\nvar CaptionParser = function CaptionParser() {\n  var isInitialized = false;\n  var captionStream; // Stores segments seen before trackId and timescale are set\n\n  var segmentCache; // Stores video track ID of the track being parsed\n\n  var trackId; // Stores the timescale of the track being parsed\n\n  var timescale; // Stores captions parsed so far\n\n  var parsedCaptions; // Stores whether we are receiving partial data or not\n\n  var parsingPartial;\n  /**\n    * A method to indicate whether a CaptionParser has been initalized\n    * @returns {Boolean}\n   **/\n\n  this.isInitialized = function () {\n    return isInitialized;\n  };\n  /**\n    * Initializes the underlying CaptionStream, SEI NAL parsing\n    * and management, and caption collection\n   **/\n\n\n  this.init = function (options) {\n    captionStream = new CaptionStream();\n    isInitialized = true;\n    parsingPartial = options ? options.isPartial : false; // Collect dispatched captions\n\n    captionStream.on('data', function (event) {\n      // Convert to seconds in the source's timescale\n      event.startTime = event.startPts / timescale;\n      event.endTime = event.endPts / timescale;\n      parsedCaptions.captions.push(event);\n      parsedCaptions.captionStreams[event.stream] = true;\n    });\n  };\n  /**\n    * Determines if a new video track will be selected\n    * or if the timescale changed\n    * @return {Boolean}\n   **/\n\n\n  this.isNewInit = function (videoTrackIds, timescales) {\n    if (videoTrackIds && videoTrackIds.length === 0 || timescales && _typeof(timescales) === 'object' && Object.keys(timescales).length === 0) {\n      return false;\n    }\n\n    return trackId !== videoTrackIds[0] || timescale !== timescales[trackId];\n  };\n  /**\n    * Parses out SEI captions and interacts with underlying\n    * CaptionStream to return dispatched captions\n    *\n    * @param {Uint8Array} segment - The fmp4 segment containing embedded captions\n    * @param {Number[]} videoTrackIds - A list of video tracks found in the init segment\n    * @param {Object.<Number, Number>} timescales - The timescales found in the init segment\n    * @see parseEmbeddedCaptions\n    * @see m2ts/caption-stream.js\n   **/\n\n\n  this.parse = function (segment, videoTrackIds, timescales) {\n    var parsedData;\n\n    if (!this.isInitialized()) {\n      return null; // This is not likely to be a video segment\n    } else if (!videoTrackIds || !timescales) {\n      return null;\n    } else if (this.isNewInit(videoTrackIds, timescales)) {\n      // Use the first video track only as there is no\n      // mechanism to switch to other video tracks\n      trackId = videoTrackIds[0];\n      timescale = timescales[trackId]; // If an init segment has not been seen yet, hold onto segment\n      // data until we have one.\n      // the ISO-BMFF spec says that trackId can't be zero, but there's some broken content out there\n    } else if (trackId === null || !timescale) {\n      segmentCache.push(segment);\n      return null;\n    } // Now that a timescale and trackId is set, parse cached segments\n\n\n    while (segmentCache.length > 0) {\n      var cachedSegment = segmentCache.shift();\n      this.parse(cachedSegment, videoTrackIds, timescales);\n    }\n\n    parsedData = parseEmbeddedCaptions(segment, trackId, timescale);\n\n    if (parsedData === null || !parsedData.seiNals) {\n      return null;\n    }\n\n    this.pushNals(parsedData.seiNals); // Force the parsed captions to be dispatched\n\n    this.flushStream();\n    return parsedCaptions;\n  };\n  /**\n    * Pushes SEI NALUs onto CaptionStream\n    * @param {Object[]} nals - A list of SEI nals parsed using `parseCaptionNals`\n    * Assumes that `parseCaptionNals` has been called first\n    * @see m2ts/caption-stream.js\n    **/\n\n\n  this.pushNals = function (nals) {\n    if (!this.isInitialized() || !nals || nals.length === 0) {\n      return null;\n    }\n\n    nals.forEach(function (nal) {\n      captionStream.push(nal);\n    });\n  };\n  /**\n    * Flushes underlying CaptionStream to dispatch processed, displayable captions\n    * @see m2ts/caption-stream.js\n   **/\n\n\n  this.flushStream = function () {\n    if (!this.isInitialized()) {\n      return null;\n    }\n\n    if (!parsingPartial) {\n      captionStream.flush();\n    } else {\n      captionStream.partialFlush();\n    }\n  };\n  /**\n    * Reset caption buckets for new data\n   **/\n\n\n  this.clearParsedCaptions = function () {\n    parsedCaptions.captions = [];\n    parsedCaptions.captionStreams = {};\n  };\n  /**\n    * Resets underlying CaptionStream\n    * @see m2ts/caption-stream.js\n   **/\n\n\n  this.resetCaptionStream = function () {\n    if (!this.isInitialized()) {\n      return null;\n    }\n\n    captionStream.reset();\n  };\n  /**\n    * Convenience method to clear all captions flushed from the\n    * CaptionStream and still being parsed\n    * @see m2ts/caption-stream.js\n   **/\n\n\n  this.clearAllCaptions = function () {\n    this.clearParsedCaptions();\n    this.resetCaptionStream();\n  };\n  /**\n    * Reset caption parser\n   **/\n\n\n  this.reset = function () {\n    segmentCache = [];\n    trackId = null;\n    timescale = null;\n\n    if (!parsedCaptions) {\n      parsedCaptions = {\n        captions: [],\n        // CC1, CC2, CC3, CC4\n        captionStreams: {}\n      };\n    } else {\n      this.clearParsedCaptions();\n    }\n\n    this.resetCaptionStream();\n  };\n\n  this.reset();\n};\n\nmodule.exports = CaptionParser;","map":null,"metadata":{},"sourceType":"module"}