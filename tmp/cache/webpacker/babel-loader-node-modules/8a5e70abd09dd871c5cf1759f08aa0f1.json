{"ast":null,"code":"/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Parse mpeg2 transport stream packets to extract basic timing information\n */\n'use strict';\n\nvar StreamTypes = require('../m2ts/stream-types.js');\n\nvar handleRollover = require('../m2ts/timestamp-rollover-stream.js').handleRollover;\n\nvar probe = {};\nprobe.ts = require('../m2ts/probe.js');\nprobe.aac = require('../aac/utils.js');\n\nvar ONE_SECOND_IN_TS = require('../utils/clock').ONE_SECOND_IN_TS;\n\nvar MP2T_PACKET_LENGTH = 188,\n    // bytes\nSYNC_BYTE = 0x47;\n/**\n * walks through segment data looking for pat and pmt packets to parse out\n * program map table information\n */\n\nvar parsePsi_ = function parsePsi_(bytes, pmt) {\n  var startIndex = 0,\n      endIndex = MP2T_PACKET_LENGTH,\n      packet,\n      type;\n\n  while (endIndex < bytes.byteLength) {\n    // Look for a pair of start and end sync bytes in the data..\n    if (bytes[startIndex] === SYNC_BYTE && bytes[endIndex] === SYNC_BYTE) {\n      // We found a packet\n      packet = bytes.subarray(startIndex, endIndex);\n      type = probe.ts.parseType(packet, pmt.pid);\n\n      switch (type) {\n        case 'pat':\n          if (!pmt.pid) {\n            pmt.pid = probe.ts.parsePat(packet);\n          }\n\n          break;\n\n        case 'pmt':\n          if (!pmt.table) {\n            pmt.table = probe.ts.parsePmt(packet);\n          }\n\n          break;\n\n        default:\n          break;\n      } // Found the pat and pmt, we can stop walking the segment\n\n\n      if (pmt.pid && pmt.table) {\n        return;\n      }\n\n      startIndex += MP2T_PACKET_LENGTH;\n      endIndex += MP2T_PACKET_LENGTH;\n      continue;\n    } // If we get here, we have somehow become de-synchronized and we need to step\n    // forward one byte at a time until we find a pair of sync bytes that denote\n    // a packet\n\n\n    startIndex++;\n    endIndex++;\n  }\n};\n/**\n * walks through the segment data from the start and end to get timing information\n * for the first and last audio pes packets\n */\n\n\nvar parseAudioPes_ = function parseAudioPes_(bytes, pmt, result) {\n  var startIndex = 0,\n      endIndex = MP2T_PACKET_LENGTH,\n      packet,\n      type,\n      pesType,\n      pusi,\n      parsed;\n  var endLoop = false; // Start walking from start of segment to get first audio packet\n\n  while (endIndex <= bytes.byteLength) {\n    // Look for a pair of start and end sync bytes in the data..\n    if (bytes[startIndex] === SYNC_BYTE && (bytes[endIndex] === SYNC_BYTE || endIndex === bytes.byteLength)) {\n      // We found a packet\n      packet = bytes.subarray(startIndex, endIndex);\n      type = probe.ts.parseType(packet, pmt.pid);\n\n      switch (type) {\n        case 'pes':\n          pesType = probe.ts.parsePesType(packet, pmt.table);\n          pusi = probe.ts.parsePayloadUnitStartIndicator(packet);\n\n          if (pesType === 'audio' && pusi) {\n            parsed = probe.ts.parsePesTime(packet);\n\n            if (parsed) {\n              parsed.type = 'audio';\n              result.audio.push(parsed);\n              endLoop = true;\n            }\n          }\n\n          break;\n\n        default:\n          break;\n      }\n\n      if (endLoop) {\n        break;\n      }\n\n      startIndex += MP2T_PACKET_LENGTH;\n      endIndex += MP2T_PACKET_LENGTH;\n      continue;\n    } // If we get here, we have somehow become de-synchronized and we need to step\n    // forward one byte at a time until we find a pair of sync bytes that denote\n    // a packet\n\n\n    startIndex++;\n    endIndex++;\n  } // Start walking from end of segment to get last audio packet\n\n\n  endIndex = bytes.byteLength;\n  startIndex = endIndex - MP2T_PACKET_LENGTH;\n  endLoop = false;\n\n  while (startIndex >= 0) {\n    // Look for a pair of start and end sync bytes in the data..\n    if (bytes[startIndex] === SYNC_BYTE && (bytes[endIndex] === SYNC_BYTE || endIndex === bytes.byteLength)) {\n      // We found a packet\n      packet = bytes.subarray(startIndex, endIndex);\n      type = probe.ts.parseType(packet, pmt.pid);\n\n      switch (type) {\n        case 'pes':\n          pesType = probe.ts.parsePesType(packet, pmt.table);\n          pusi = probe.ts.parsePayloadUnitStartIndicator(packet);\n\n          if (pesType === 'audio' && pusi) {\n            parsed = probe.ts.parsePesTime(packet);\n\n            if (parsed) {\n              parsed.type = 'audio';\n              result.audio.push(parsed);\n              endLoop = true;\n            }\n          }\n\n          break;\n\n        default:\n          break;\n      }\n\n      if (endLoop) {\n        break;\n      }\n\n      startIndex -= MP2T_PACKET_LENGTH;\n      endIndex -= MP2T_PACKET_LENGTH;\n      continue;\n    } // If we get here, we have somehow become de-synchronized and we need to step\n    // forward one byte at a time until we find a pair of sync bytes that denote\n    // a packet\n\n\n    startIndex--;\n    endIndex--;\n  }\n};\n/**\n * walks through the segment data from the start and end to get timing information\n * for the first and last video pes packets as well as timing information for the first\n * key frame.\n */\n\n\nvar parseVideoPes_ = function parseVideoPes_(bytes, pmt, result) {\n  var startIndex = 0,\n      endIndex = MP2T_PACKET_LENGTH,\n      packet,\n      type,\n      pesType,\n      pusi,\n      parsed,\n      frame,\n      i,\n      pes;\n  var endLoop = false;\n  var currentFrame = {\n    data: [],\n    size: 0\n  }; // Start walking from start of segment to get first video packet\n\n  while (endIndex < bytes.byteLength) {\n    // Look for a pair of start and end sync bytes in the data..\n    if (bytes[startIndex] === SYNC_BYTE && bytes[endIndex] === SYNC_BYTE) {\n      // We found a packet\n      packet = bytes.subarray(startIndex, endIndex);\n      type = probe.ts.parseType(packet, pmt.pid);\n\n      switch (type) {\n        case 'pes':\n          pesType = probe.ts.parsePesType(packet, pmt.table);\n          pusi = probe.ts.parsePayloadUnitStartIndicator(packet);\n\n          if (pesType === 'video') {\n            if (pusi && !endLoop) {\n              parsed = probe.ts.parsePesTime(packet);\n\n              if (parsed) {\n                parsed.type = 'video';\n                result.video.push(parsed);\n                endLoop = true;\n              }\n            }\n\n            if (!result.firstKeyFrame) {\n              if (pusi) {\n                if (currentFrame.size !== 0) {\n                  frame = new Uint8Array(currentFrame.size);\n                  i = 0;\n\n                  while (currentFrame.data.length) {\n                    pes = currentFrame.data.shift();\n                    frame.set(pes, i);\n                    i += pes.byteLength;\n                  }\n\n                  if (probe.ts.videoPacketContainsKeyFrame(frame)) {\n                    var firstKeyFrame = probe.ts.parsePesTime(frame); // PTS/DTS may not be available. Simply *not* setting\n                    // the keyframe seems to work fine with HLS playback\n                    // and definitely preferable to a crash with TypeError...\n\n                    if (firstKeyFrame) {\n                      result.firstKeyFrame = firstKeyFrame;\n                      result.firstKeyFrame.type = 'video';\n                    } else {\n                      // eslint-disable-next-line\n                      console.warn('Failed to extract PTS/DTS from PES at first keyframe. ' + 'This could be an unusual TS segment, or else mux.js did not ' + 'parse your TS segment correctly. If you know your TS ' + 'segments do contain PTS/DTS on keyframes please file a bug ' + 'report! You can try ffprobe to double check for yourself.');\n                    }\n                  }\n\n                  currentFrame.size = 0;\n                }\n              }\n\n              currentFrame.data.push(packet);\n              currentFrame.size += packet.byteLength;\n            }\n          }\n\n          break;\n\n        default:\n          break;\n      }\n\n      if (endLoop && result.firstKeyFrame) {\n        break;\n      }\n\n      startIndex += MP2T_PACKET_LENGTH;\n      endIndex += MP2T_PACKET_LENGTH;\n      continue;\n    } // If we get here, we have somehow become de-synchronized and we need to step\n    // forward one byte at a time until we find a pair of sync bytes that denote\n    // a packet\n\n\n    startIndex++;\n    endIndex++;\n  } // Start walking from end of segment to get last video packet\n\n\n  endIndex = bytes.byteLength;\n  startIndex = endIndex - MP2T_PACKET_LENGTH;\n  endLoop = false;\n\n  while (startIndex >= 0) {\n    // Look for a pair of start and end sync bytes in the data..\n    if (bytes[startIndex] === SYNC_BYTE && bytes[endIndex] === SYNC_BYTE) {\n      // We found a packet\n      packet = bytes.subarray(startIndex, endIndex);\n      type = probe.ts.parseType(packet, pmt.pid);\n\n      switch (type) {\n        case 'pes':\n          pesType = probe.ts.parsePesType(packet, pmt.table);\n          pusi = probe.ts.parsePayloadUnitStartIndicator(packet);\n\n          if (pesType === 'video' && pusi) {\n            parsed = probe.ts.parsePesTime(packet);\n\n            if (parsed) {\n              parsed.type = 'video';\n              result.video.push(parsed);\n              endLoop = true;\n            }\n          }\n\n          break;\n\n        default:\n          break;\n      }\n\n      if (endLoop) {\n        break;\n      }\n\n      startIndex -= MP2T_PACKET_LENGTH;\n      endIndex -= MP2T_PACKET_LENGTH;\n      continue;\n    } // If we get here, we have somehow become de-synchronized and we need to step\n    // forward one byte at a time until we find a pair of sync bytes that denote\n    // a packet\n\n\n    startIndex--;\n    endIndex--;\n  }\n};\n/**\n * Adjusts the timestamp information for the segment to account for\n * rollover and convert to seconds based on pes packet timescale (90khz clock)\n */\n\n\nvar adjustTimestamp_ = function adjustTimestamp_(segmentInfo, baseTimestamp) {\n  if (segmentInfo.audio && segmentInfo.audio.length) {\n    var audioBaseTimestamp = baseTimestamp;\n\n    if (typeof audioBaseTimestamp === 'undefined') {\n      audioBaseTimestamp = segmentInfo.audio[0].dts;\n    }\n\n    segmentInfo.audio.forEach(function (info) {\n      info.dts = handleRollover(info.dts, audioBaseTimestamp);\n      info.pts = handleRollover(info.pts, audioBaseTimestamp); // time in seconds\n\n      info.dtsTime = info.dts / ONE_SECOND_IN_TS;\n      info.ptsTime = info.pts / ONE_SECOND_IN_TS;\n    });\n  }\n\n  if (segmentInfo.video && segmentInfo.video.length) {\n    var videoBaseTimestamp = baseTimestamp;\n\n    if (typeof videoBaseTimestamp === 'undefined') {\n      videoBaseTimestamp = segmentInfo.video[0].dts;\n    }\n\n    segmentInfo.video.forEach(function (info) {\n      info.dts = handleRollover(info.dts, videoBaseTimestamp);\n      info.pts = handleRollover(info.pts, videoBaseTimestamp); // time in seconds\n\n      info.dtsTime = info.dts / ONE_SECOND_IN_TS;\n      info.ptsTime = info.pts / ONE_SECOND_IN_TS;\n    });\n\n    if (segmentInfo.firstKeyFrame) {\n      var frame = segmentInfo.firstKeyFrame;\n      frame.dts = handleRollover(frame.dts, videoBaseTimestamp);\n      frame.pts = handleRollover(frame.pts, videoBaseTimestamp); // time in seconds\n\n      frame.dtsTime = frame.dts / ONE_SECOND_IN_TS;\n      frame.ptsTime = frame.dts / ONE_SECOND_IN_TS;\n    }\n  }\n};\n/**\n * inspects the aac data stream for start and end time information\n */\n\n\nvar inspectAac_ = function inspectAac_(bytes) {\n  var endLoop = false,\n      audioCount = 0,\n      sampleRate = null,\n      timestamp = null,\n      frameSize = 0,\n      byteIndex = 0,\n      packet;\n\n  while (bytes.length - byteIndex >= 3) {\n    var type = probe.aac.parseType(bytes, byteIndex);\n\n    switch (type) {\n      case 'timed-metadata':\n        // Exit early because we don't have enough to parse\n        // the ID3 tag header\n        if (bytes.length - byteIndex < 10) {\n          endLoop = true;\n          break;\n        }\n\n        frameSize = probe.aac.parseId3TagSize(bytes, byteIndex); // Exit early if we don't have enough in the buffer\n        // to emit a full packet\n\n        if (frameSize > bytes.length) {\n          endLoop = true;\n          break;\n        }\n\n        if (timestamp === null) {\n          packet = bytes.subarray(byteIndex, byteIndex + frameSize);\n          timestamp = probe.aac.parseAacTimestamp(packet);\n        }\n\n        byteIndex += frameSize;\n        break;\n\n      case 'audio':\n        // Exit early because we don't have enough to parse\n        // the ADTS frame header\n        if (bytes.length - byteIndex < 7) {\n          endLoop = true;\n          break;\n        }\n\n        frameSize = probe.aac.parseAdtsSize(bytes, byteIndex); // Exit early if we don't have enough in the buffer\n        // to emit a full packet\n\n        if (frameSize > bytes.length) {\n          endLoop = true;\n          break;\n        }\n\n        if (sampleRate === null) {\n          packet = bytes.subarray(byteIndex, byteIndex + frameSize);\n          sampleRate = probe.aac.parseSampleRate(packet);\n        }\n\n        audioCount++;\n        byteIndex += frameSize;\n        break;\n\n      default:\n        byteIndex++;\n        break;\n    }\n\n    if (endLoop) {\n      return null;\n    }\n  }\n\n  if (sampleRate === null || timestamp === null) {\n    return null;\n  }\n\n  var audioTimescale = ONE_SECOND_IN_TS / sampleRate;\n  var result = {\n    audio: [{\n      type: 'audio',\n      dts: timestamp,\n      pts: timestamp\n    }, {\n      type: 'audio',\n      dts: timestamp + audioCount * 1024 * audioTimescale,\n      pts: timestamp + audioCount * 1024 * audioTimescale\n    }]\n  };\n  return result;\n};\n/**\n * inspects the transport stream segment data for start and end time information\n * of the audio and video tracks (when present) as well as the first key frame's\n * start time.\n */\n\n\nvar inspectTs_ = function inspectTs_(bytes) {\n  var pmt = {\n    pid: null,\n    table: null\n  };\n  var result = {};\n  parsePsi_(bytes, pmt);\n\n  for (var pid in pmt.table) {\n    if (pmt.table.hasOwnProperty(pid)) {\n      var type = pmt.table[pid];\n\n      switch (type) {\n        case StreamTypes.H264_STREAM_TYPE:\n          result.video = [];\n          parseVideoPes_(bytes, pmt, result);\n\n          if (result.video.length === 0) {\n            delete result.video;\n          }\n\n          break;\n\n        case StreamTypes.ADTS_STREAM_TYPE:\n          result.audio = [];\n          parseAudioPes_(bytes, pmt, result);\n\n          if (result.audio.length === 0) {\n            delete result.audio;\n          }\n\n          break;\n\n        default:\n          break;\n      }\n    }\n  }\n\n  return result;\n};\n/**\n * Inspects segment byte data and returns an object with start and end timing information\n *\n * @param {Uint8Array} bytes The segment byte data\n * @param {Number} baseTimestamp Relative reference timestamp used when adjusting frame\n *  timestamps for rollover. This value must be in 90khz clock.\n * @return {Object} Object containing start and end frame timing info of segment.\n */\n\n\nvar inspect = function inspect(bytes, baseTimestamp) {\n  var isAacData = probe.aac.isLikelyAacData(bytes);\n  var result;\n\n  if (isAacData) {\n    result = inspectAac_(bytes);\n  } else {\n    result = inspectTs_(bytes);\n  }\n\n  if (!result || !result.audio && !result.video) {\n    return null;\n  }\n\n  adjustTimestamp_(result, baseTimestamp);\n  return result;\n};\n\nmodule.exports = {\n  inspect: inspect,\n  parseAudioPes_: parseAudioPes_\n};","map":null,"metadata":{},"sourceType":"module"}